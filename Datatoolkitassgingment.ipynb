{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA TOOLKIT"
      ],
      "metadata": {
        "id": "VnhHa5gBz8VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.What is NumPy, and why is it widely used in Python?**\n",
        "\n",
        "NumPy (short for Numerical Python) is a **powerful open-source library** in Python used for numerical computing. It provides tools for working with large, multi-dimensional arrays and matrices, along with a wide **collection of high-level mathematical functions** to operate on these arrays efficiently.\n",
        "\n",
        "- A **Python library** that adds support for n-dimensional arrays (called ndarray).\n",
        "\n",
        "- Provides **vectorized operations**, meaning operations are applied on whole arrays at once (instead of element by element).\n",
        "\n",
        "- Written in C and optimized for speed, making it much faster than using plain Python lists for **numerical tasks**.\n",
        "\n",
        "**üîπ Why NumPy is widely used:**\n",
        " **1.Efficient array operations**\n",
        "\n",
        "- NumPy arrays use less memory and are faster than Python lists.\n",
        "\n",
        "- Example: Multiplying two arrays with * in NumPy is element-wise and optimized.\n",
        "\n",
        "**2.Mathematical functions**\n",
        "\n",
        "- Provides functions for linear algebra, statistics, Fourier transforms, random number generation, etc.\n",
        "\n",
        "**3.Integration with other libraries**\n",
        "\n",
        "- Core dependency for **pandas, scikit-learn, TensorFlow, PyTorch, Matplotlib, and many more**.\n",
        "\n",
        "- Acts as the foundation of the **scientific Python ecosystem**.\n",
        "\n",
        "**4.Convenient slicing and indexing**\n",
        "\n",
        "- More powerful than **Python lists** (supports multi-dimensional slicing, boolean indexing, fancy indexing).\n",
        "\n",
        "**5.Broadcasting**\n",
        "\n",
        "- Allows **operations between arrays of different shapes** without explicitly writing loops.\n",
        "\n",
        "**6.Cross-platform**\n",
        "\n",
        "- Works across different **operating systems and hardware** (including GPU acceleration through libraries like CuPy).\n"
      ],
      "metadata": {
        "id": "hOwrXs2Ez-8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.How does broadcasting work in NumPy?**\n",
        "\n",
        "**Broadcasting** is a set of rules that NumPy follows when performing **arithmetic operations on arrays** with different shapes.\n",
        "\n",
        "Instead of requiring arrays to be the exact same shape, NumPy tries to ‚Äústretch‚Äù the **smaller array across the larger one so that element-wise*** operations are possible without actually copying data.\n",
        "\n",
        "**üîπ Rules of Broadcasting**\n",
        "- Compare their shapes from right to left.\n",
        "\n",
        "- Dimensions are compatible if:\n",
        "\n",
        "**They are equal, or** **One of them is 1**.\n",
        "\n",
        "- If one array has fewer dimensions, NumPy adds leading 1s to make the shapes match.\n",
        "\n",
        "- If dimensions are still incompatible, NumPy raises an error.\n"
      ],
      "metadata": {
        "id": "_ZEXfBF70e84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.What is a Pandas DataFrame?**\n",
        "\n",
        "A **Pandas DataFrame** is a **two-dimensional, tabular data structure** in the **pandas library** (built on top of NumPy).\n",
        "\n",
        "It is like a **spreadsheet or SQL table in Python** ‚Äî with rows and columns, where:\n",
        "\n",
        "- **ROWS ‚Üí** represent observations/records\n",
        "\n",
        "- **COLUMNS ‚Üí** represent features/attributes\n",
        "\n",
        "Each column can hold different data types (integer, float, string, datetime, etc.)\n",
        "\n",
        "üîπ **KEY FEATURE OF DATAFRAME**\n",
        "- **1.Labeled axes ‚Üí** Rows (index) and Columns (column names).\n",
        "\n",
        "- **2.Heterogeneous data ‚Üí** Different data types in different columns.\n",
        "\n",
        "- **3.Size mutable ‚Üí** Can add or drop rows/columns.\n",
        "\n",
        "- **4.Data alignment ‚Üí** Handles missing data gracefully (NaN).\n",
        "\n",
        "- **5.Built-in methods ‚Üí** For filtering, grouping, aggregation, merging, reshaping, etc.\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "8BbP--aW4gBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from a dictionary\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"Age\": [25, 30, 35],\n",
        "    \"City\": [\"New York\", \"London\", \"Paris\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "1eueOZ2R7Lle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.Explain the use of the groupby() method in Pandas?**\n",
        "\n",
        "The groupby() method in Pandas is used to **split data into groups** based on the values in one or more columns, and then apply **aggregation, transformation, or filtering operations** on those groups.\n",
        "\n",
        "It follows the ‚Äú**split ‚Üí apply ‚Üí combine**‚Äù process:\n",
        "\n",
        "- **1.Split** ‚Äì Divide the data into groups (by column values).\n",
        "\n",
        "- **2.Apply** ‚Äì Apply a function (like sum, mean, count, etc.) to each group.\n",
        "\n",
        "- **3.Combine** ‚Äì Merge the results back into a DataFrame.\n",
        "\n",
        "**SYNTAX:**\n",
        "\n",
        "df.groupby('column_name')\n",
        "\n",
        "df.groupby(['col1', 'col2'])\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "bHSp5RAm7NTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Department\": [\"HR\", \"HR\", \"IT\", \"IT\", \"Finance\"],\n",
        "    \"Employee\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"],\n",
        "    \"Salary\": [50000, 55000, 60000, 65000, 70000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Group by Department and calculate average salary\n",
        "result = df.groupby(\"Department\")[\"Salary\"].mean()\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "eVE8dgyU7WeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.Why is Seaborn preferred for statistical visualizations?**\n",
        "\n",
        "**Seaborn is a Python data visualization** library built on top of Matplotlib.\n",
        "It is preferred for **statistical visualizations because it provides a high-level, easy-to-use interface and comes with built-in support** for statistical plots.\n",
        "\n",
        "- **KEY REASON SEABORN IS PREPARERD:**\n",
        "\n",
        "**1.Simpler Syntax & High-Level API**\n",
        "\n",
        "- Seaborn lets you create complex statistical plots with just one line of code, whereas **Matplotlib** often requires many lines.\n",
        "\n",
        "**2.Beautiful Default Styles**\n",
        "\n",
        "- **Seaborn** has attractive, **modern default themes that make plots** look professional without extra formatting.\n",
        "\n",
        "**3.Built-in Statistical Functions**\n",
        "\n",
        "- Automatically handles statistical **estimation and visualization (e.g., confidence intervals**, regression lines).\n",
        "\n",
        "- **Example**: sns.regplot() adds regression line + confidence interval automatically.\n",
        "\n",
        "**4.ntegration with Pandas DataFrames**\n",
        "\n",
        "- Works directly with Pandas DataFrames and column names, reducing the need for manual indexing.\n",
        "\n",
        "**5.Specialized Statistical Plots**\n",
        "\n",
        "- Provides advanced plots that Matplotlib doesn‚Äôt have out-of-the-box, like:\n",
        "\n",
        "- Heatmaps (sns.heatmap)\n",
        "\n",
        "- Pair plots (sns.pairplot)\n",
        "\n",
        "- Violin plots (sns.violinplot)\n",
        "\n",
        "- Distribution plots (sns.histplot, sns.kdeplot)\n",
        "\n",
        "**6.Automatic Handling of Categorical Data**\n",
        "\n",
        "- Seaborn makes it easy to **compare categories visually** (bar plots, box plots, swarm plots, etc.).\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "155Kdwg57cNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(df[\"Salary\"], bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.xlabel(\"Salary\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Salary Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KbYDybP673Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Differences Between NumPy Arrays and Python Lists:**\n",
        "\n",
        "\n",
        "| Feature                     | **Python List**                                                              | **NumPy Array (`ndarray`)**                                                  |\n",
        "| --------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n",
        "| **Data Type**               | Can store **heterogeneous data** (int, float, string, etc.) in the same list | Stores **homogeneous data** (all elements must be of the same type)          |\n",
        "| **Memory Usage**            | Stores data as **objects**, so it is less memory-efficient                   | Stores data in **contiguous blocks** of memory ‚Üí more efficient              |\n",
        "| **Performance**             | Slower for numerical operations (uses Python loops)                          | Much faster (vectorized operations implemented in C)                         |\n",
        "| **Functionality**           | Only basic operations (append, pop, slicing)                                 | Supports advanced mathematical, linear algebra, statistical operations       |\n",
        "| **Dimension Support**       | 1D only (list of lists for 2D, but clunky)                                   | Supports **n-dimensional arrays** (matrix, tensor, etc.)                     |\n",
        "| **Broadcasting**            | Not supported                                                                | Fully supports **broadcasting** (operations on arrays of different shapes)   |\n",
        "| **Element-wise Operations** | Must use loops or list comprehensions                                        | Directly supports element-wise operations (e.g., `a + b`)                    |\n",
        "| **Integration**             | General-purpose                                                              | Backbone for data science libraries (Pandas, Scikit-learn, TensorFlow, etc.) |\n",
        "\n",
        "**EXAMPLE**"
      ],
      "metadata": {
        "id": "FmFtEOC88NyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [1, 2, 3, 4]\n",
        "result = [x*2 for x in lst]\n",
        "print(result)\n",
        "\n",
        "\n",
        "- **NUMPY ARRAY**\n",
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "result = arr * 2\n",
        "print(result)"
      ],
      "metadata": {
        "id": "oHzJXPgp8SSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.What is a heatmap, and when should it be used?**\n",
        "\n",
        "A **heatmap is a data visualization technique** that uses color shading to represent values in a 2D matrix or table.\n",
        "\n",
        "- Each cell in the table is *colored** based on its value.\n",
        "\n",
        "- **Darker or brighter colors** usually represent higher or lower values (depending on the color scale).\n",
        "\n",
        "In Python, heatmaps are commonly created with **Seaborn (sns.heatmap) or Matplotlib.**\n",
        "\n",
        "**EXAMPLE**"
      ],
      "metadata": {
        "id": "jgBNRx2R8X5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2, 3],\n",
        "                 [4, 5, 6],\n",
        "                 [7, 8, 9]])\n",
        "\n",
        "sns.heatmap(data, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()\n",
        "\n",
        "üîπ **When Should a Heatmap Be Used**:"
      ],
      "metadata": {
        "id": "MQ3x7fd3BMZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **When Should a Heatmap Be Used**:\n",
        "\n",
        "**1.Correlation Analysis**\n",
        "\n",
        "- To show relationships between variables in a dataset.\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"viridis\")\n",
        "\n",
        "**2.Visualizing Matrices**\n",
        "\n",
        "- Great for showing confusion matrices in machine learning.\n",
        "\n",
        "**3.Highlighting Patterns**\n",
        "\n",
        "- Easy to spot trends, clusters, or anomalies in data (e.g., sales over time, temperature variations).\n",
        "\n",
        "**4.Comparisons in Large Data**\n",
        "\n",
        "- Makes large numeric datasets easier to interpret visually."
      ],
      "metadata": {
        "id": "4geYlMiDBcvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. What does the term ‚Äúvectorized operation‚Äù mean in NumPy?**\n",
        "\n",
        "A vectorized operation means **performing an operation** on an entire array (or batch of data) at once, without writing explicit **Python loops**.\n",
        "\n",
        "- NumPy implements these operations in **optimized C code** under the hood.\n",
        "\n",
        "- This makes them much faster and more concise than looping through elements in **pure Python.**\n",
        "\n",
        "üîπ **EXAMPLE**\n",
        "\n",
        "‚ùå **Without Vectorization** (using a loop)"
      ],
      "metadata": {
        "id": "rP1RdqvsCDh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = [1, 2, 3, 4]\n",
        "result = []\n",
        "for n in numbers:\n",
        "    result.append(n * 2)\n",
        "\n",
        "print(result)  # [2, 4, 6, 8]\n",
        "\n",
        "#%% md\n",
        "‚úÖ **With Vectorization** (NumPy)\n",
        "#%%\n",
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "result = arr * 2\n",
        "\n",
        "print(result)  # [2 4 6 8]"
      ],
      "metadata": {
        "id": "monTU578CL-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Why Vectorized Operations are Important**\n",
        "- **1.Speed ‚Üí** Runs in C (much faster than Python loops).\n",
        "\n",
        "- **2.Simplicity ‚Üí** Cleaner, more readable code.\n",
        "\n",
        "- **3.Memory Efficiency ‚Üí** No need for intermediate lists.\n",
        "\n",
        "- **4.Mathematical Expressiveness ‚Üí** Code looks like real math equations."
      ],
      "metadata": {
        "id": "23Rp604sCWB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.How does Matplotlib differ from Plotly?**\n",
        "\n",
        "- üîπ **KEY DIFFERENCES BETWEEN MATPLOTLIB & PLOTLY**\n",
        "\n",
        "| Feature           | **Matplotlib**                                                                    | **Plotly**                                                            |\n",
        "| ----------------- | --------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
        "| **Type**          | Low-level, static plotting library                                                | High-level, interactive plotting library                              |\n",
        "| **Interactivity** | Mostly static (can use `mpl_interactions` or `%matplotlib notebook`, but limited) | Fully interactive (zoom, pan, hover tooltips, clickable legends)      |\n",
        "| **Ease of Use**   | Requires more code for styling and customization                                  | Easier for interactive dashboards and quick interactive plots         |\n",
        "| **Customization** | Very flexible, but verbose                                                        | Limited compared to Matplotlib, but sufficient for most               |\n",
        "| **Integration**   | Works well with Pandas, NumPy, Seaborn                                            | Works with Pandas, NumPy, Dash (for web apps)                         |\n",
        "| **Output**        | Best for static plots (PDFs, PNGs, scientific papers)                             | Best for interactive visualizations (web, dashboards)                 |\n",
        "| **Performance**   | Handles large datasets efficiently                                                | Can be slower for very large datasets (due to interactivity overhead) |\n",
        "| **3D Support**    | Basic 3D plotting (`mpl_toolkits.mplot3d`)                                        | Strong 3D plotting (interactive 3D scatter, surface, mesh)            |\n",
        "\n",
        "**EXAMPLE**\n",
        "- **Matplotlib** (Static Plot)"
      ],
      "metadata": {
        "id": "jPeIwCm5CZpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [1, 2, 3, 4]\n",
        "y = [10, 20, 25, 30]\n",
        "\n",
        "plt.plot(x, y, marker=\"o\")\n",
        "plt.title(\"Matplotlib Example\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.show()\n",
        "\n",
        "**Plotly** (Interactive Plot)\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "x = [1, 2, 3, 4]\n",
        "y = [10, 20, 25, 30]\n",
        "\n",
        "fig = px.line(x=x, y=y, markers=True, title=\"Plotly Example\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bW3oMlkUCzQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.What is the significance of hierarchical indexing in Pandas?**\n",
        "\n",
        "**Hierarchical indexing** (also called a MultiIndex) in Pandas allows you to have multiple levels of row or column indexes in a DataFrame or Series.\n",
        "\n",
        "Instead of just one row label, you can use two or more indexes, which creates a tree-like structure.\n",
        "\n",
        "**Why is it Significant**:\n",
        "\n",
        " **1.Represents Higher-Dimensional Data in 2D**\n",
        "\n",
        "- Lets you work with higher-dimensional data (like 3D or 4D) in a 2D DataFrame format.\n",
        "\n",
        "**2.More Powerful Data Selection**:\n",
        "\n",
        "- You can access data using multiple keys (e.g., df.loc[('India', 'Delhi')]).\n",
        "\n",
        "**3.Better Data Organization**:\n",
        "\n",
        "- Useful for grouping and working with datasets that have natural hierarchical structures (e.g., Country ‚Üí State ‚Üí City).\n",
        "\n",
        "**4.Works Seamlessly with GroupBy**\n",
        "\n",
        "- Many groupby() operations return results with a MultiIndex.\n"
      ],
      "metadata": {
        "id": "p_mv_oUMC9wY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.What is the role of Seaborn‚Äôs pairplot() function?**\n",
        "\n",
        "Seaborn‚Äôs pairplot() is a **high-level visualization tool used to quickly explore the relationships between multiple variables in a dataset**.\n",
        "\n",
        "It creates a matrix of plots:\n",
        "\n",
        "- **Diagonal ‚Üí** Distribution of each variable (histogram or KDE).\n",
        "\n",
        "- **Off-diagonal ‚Üí** Scatter plots showing relationships between pairs of variables.\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "vOtW5S_mDFMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load example dataset\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Pairplot with hue for species\n",
        "sns.pairplot(iris, hue=\"species\", diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RJfP8PDnDJgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.What is the purpose of the describe() function in Pandas?**\n",
        "\n",
        "The describe() function in **Pandas is used to generate summary statistics** of a DataFrame (or Series).\n",
        "It gives you a quick overview of the distribution and key statistics of your data.\n",
        "\n",
        "üîπ **What It Returns**\n",
        "\n",
        "By default (for numerical columns), it provides:\n",
        "\n",
        "- **count ‚Üí** Number of non-null values\n",
        "\n",
        "- **mean ‚Üí** Average value\n",
        "\n",
        "- **std ‚Üí** Standard deviation (spread of values)\n",
        "\n",
        "- **min ‚Üí** Minimum value\n",
        "\n",
        "- **25% ‚Üí** First quartile (Q1)\n",
        "\n",
        "- **50% ‚Üí** Median (Q2)\n",
        "\n",
        "- **75% ‚Üí** Third quartile (Q3)\n",
        "\n",
        "- **max ‚Üí** Maximum value\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "766lkqukDiA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Age\": [22, 25, 29, 30, 32, 35],\n",
        "    \"Salary\": [30000, 35000, 40000, 42000, 50000, 60000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "DqxEkdsJDkjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. Why is handling missing data important in Pandas?**\n",
        "\n",
        "**1.Maintains Data Quality**\n",
        "\n",
        "- Missing values can reduce the **reliability and accuracy** of your analysis.\n",
        "\n",
        "- For example, calculating an **Avarage** salary with missing entries might give misleading results.\n",
        "\n",
        "**2.Prevents Errors in Analysis**\n",
        "\n",
        "- Many Pandas/NumPy functions (like mean(), sum(), corr()) may return NaN if missing values are not handled.\n",
        "\n",
        "- Machine learning models (like in scikit-learn) often cannot handle missing values directly.\n",
        "\n",
        "**3.Preserves Statistical Validity**\n",
        "\n",
        "- Missing data can bias results if not **treated properly**.\n",
        "\n",
        "- **Example:** If younger people‚Äôs ages are missing, the average age will be incorrectly higher.\n",
        "\n",
        "**4.Enables Better Modeling**\n",
        "\n",
        "- Models require complete, **clean data** to learn patterns correctly.\n",
        "\n",
        "- Handling missing **data ensures models** don‚Äôt fail or produce incorrect predictions.\n",
        "\n",
        "**5.Improves Decision-Making**\n",
        "\n",
        "- Clean datasets with no **unexpected gaps** lead to better business insights and **trustworthy reports**.\n",
        "\n",
        "**How Pandas Helps Handle Missing Data**\n",
        "\n",
        "- Pandas provides built-in functions like:\n",
        "\n",
        "- df.isnull() **‚Üí** Detect missing values\n",
        "\n",
        "- df.dropna() **‚Üí** Remove missing values\n",
        "\n",
        "- df.fillna(value) **‚Üí** Replace missing values with a constant, mean, median, mode, etc.\n",
        "\n",
        "- df.interpolate() **‚Üí** Estimate missing values using interpolation\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "QSlMvLy-Do-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "        \"Age\": [25, None, 30],\n",
        "        \"Salary\": [50000, 60000, None]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(df)\n",
        "\n",
        "# Fill missing Age with mean, Salary with 0\n",
        "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
        "df[\"Salary\"].fillna(0, inplace=True)\n",
        "\n",
        "print(\"\\nAfter Handling Missing Data:\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "L5DteFIVboDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.What are the benefits of using Plotly for data visualization?**\n",
        "\n",
        "**Benefits of Using Plotly for Data Visualization**\n",
        "\n",
        "**1.Interactivity by Default**\n",
        "\n",
        "- Unlike Matplotlib/Seaborn (which are mostly static), **Plotly charts** are interactive.\n",
        "\n",
        "- Features: zoom, pan, hover **tooltips, toggle legend items**, export as images.\n",
        "\n",
        "**2.Beautiful Visuals with Minimal Code**\n",
        "\n",
        "- Provides modern, **polished plots** without much customization.\n",
        "\n",
        "- Example: px.line() creates a fully interactive line chart in one line.\n",
        "\n",
        "**3.Wide Range of Charts**\n",
        "\n",
        "- Supports simple charts (line, bar, scatter, pie) and advanced ones:\n",
        "\n",
        "- 3D scatter, surface plots\n",
        "\n",
        "- Choropleth (maps)\n",
        "\n",
        "- Time-series charts\n",
        "\n",
        "- Sankey diagrams, Treemaps, Sunbursts\n",
        "\n",
        "**4.Seamless Pandas & NumPy Integration**\n",
        "\n",
        "- Works directly with DataFrames ‚Üí just pass column names **instead of manually extracting arrays.**"
      ],
      "metadata": {
        "id": "u_Hm1Xymbs4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.How does NumPy handle multidimensional arrays?**\n",
        "\n",
        "**1. REPRESENTATION**\n",
        "\n",
        "A NumPy array can have any number of dimensions:\n",
        "\n",
        "- **1.1D ‚Üí** vector ([1, 2, 3])\n",
        "\n",
        "- **2.2D ‚Üí** matrix ([[1, 2], [3, 4]])\n",
        "\n",
        "- **3.3D ‚Üí** tensor ([[[1,2],[3,4]], [[5,6],[7,8]]])\n",
        "\n",
        "and so on‚Ä¶\n",
        "\n",
        "The number of **dimensions** is called the rank of the array.\n",
        "\n",
        "Dimensions themselves are referred to as **axes**.\n",
        "\n",
        "**EXAMPLE**:\n"
      ],
      "metadata": {
        "id": "n57880u9b1LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([[1, 2, 3],\n",
        "                [4, 5, 6]])\n",
        "print(arr.ndim)  # 2D array\n",
        "print(arr.shape) # (2, 3) ‚Üí 2 rows, 3 columns"
      ],
      "metadata": {
        "id": "lorGISK_b6NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.SHAPE & STRIDES**\n",
        "\n",
        "- **Shape ‚Üí** A tuple describing the size along each axis.\n",
        "\n",
        "- **Example:** a 3√ó4√ó2 array has shape = (3, 4, 2)\n",
        "\n",
        "- **Strides ‚Üí** Tell NumPy how many bytes to step in each dimension when traversing.\n",
        "\n",
        "- This makes slicing and reshaping very efficient without copying data.\n",
        "\n",
        "**3.INDEXING & SLICING**\n",
        "\n",
        "- NumPy supports multidimensional indexing:\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "2QeQmHNeb-L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([[10, 20, 30],\n",
        "                [40, 50, 60]])\n",
        "print(arr[1, 2])   # 60\n",
        "print(arr[:, 1])   # [20, 50] ‚Üí second column"
      ],
      "metadata": {
        "id": "zz5uQmtjcWOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.VECTORIZED OPERATIONS**:\n",
        "- Operations are applied element-wise across dimensions:\n",
        "\n",
        "**EXAMPLE**"
      ],
      "metadata": {
        "id": "DryVjs9Dck_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[10, 20], [30, 40]])\n",
        "print(A + B)  # element-wise addition"
      ],
      "metadata": {
        "id": "7OuHtX57dFzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy uses **broadcasting** rules to handle operations on arrays of different shapes.\n",
        "\n",
        "- **5.RESHAPING & TRANSPOING**\n",
        "\n",
        "- Arrays can be reshaped without changing data\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "I8tdCVUgdGvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(12).reshape(3, 4)\n",
        "print(arr.T)   # transpose (swap axes)"
      ],
      "metadata": {
        "id": "-iEJtT58dM7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16.What is the role of Bokeh in data visualization?**\n",
        " **Role of Bokeh in Data Visualization**\n",
        "\n",
        "**1.Interactive Visualizations**\n",
        "\n",
        "- Unlike static libraries (e.g., Matplotlib), Bokeh **emphasizes interactivity (zooming, panning, tooltips, filtering)**.\n",
        "\n",
        "- **Example:** hover over a point to see details, or drag to **zoom into regions**.\n",
        "\n",
        "**2.Web-Friendly Output**\n",
        "\n",
        "- Bokeh generates **visualizations that can be rendered** in browsers using HTML, JavaScript, and JSON.\n",
        "\n",
        "- It integrates seamlessly with **Flask, Django, or Jupyter Notebooks**.\n",
        "\n",
        "**3.Handling Large Datasets**\n",
        "\n",
        "- Bokeh is optimized to work with large or streaming datasets.\n",
        "\n",
        "- It can use a Bokeh server to **stream and update data** in real time.\n",
        "\n",
        "**4.High-Level Charts & Customization**\n",
        "\n",
        "- Provides **high-level charting** (bar, line, scatter, heatmaps, etc.).\n",
        "\n",
        "- Also allows low-level control to build custom, **complex dashboards**.\n",
        "\n",
        "**5.Integration with Other Tools**\n",
        "\n",
        "- Works well with **Pandas, NumPy, and Dask for data manipulation.**\n",
        "\n",
        "- Can embed plots into **web apps or dashboards** (similar to Plotly Dash).\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "LWIYIX54dZX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show\n",
        "\n",
        "# Create a simple line plot\n",
        "p = figure(title=\"Simple Line Example\", x_axis_label='x', y_axis_label='y')\n",
        "p.line([1, 2, 3, 4], [6, 7, 2, 4], line_width=2)\n",
        "\n",
        "show(p)  # Opens in a browser"
      ],
      "metadata": {
        "id": "bYPxPvnOdn_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.Explain the difference between apply() and map() in Pandas?**\n",
        "\n",
        "\n",
        "\n",
        "| Feature      | `map()`                             | `apply()`                                   |\n",
        "| ------------ | ----------------------------------- | ------------------------------------------- |\n",
        "| Works on     | **Series only**                     | **Series & DataFrame**                      |\n",
        "| Input types  | Function, dictionary, Series        | Function (any Python function, NumPy ufunc) |\n",
        "| Output       | Transformed Series                  | Series (if applied on Series) or DataFrame  |\n",
        "| Axis support | ‚ùå (not needed, always element-wise) | ‚úÖ (`axis=0` for columns, `axis=1` for rows) |\n",
        "\n",
        "** 1. map()**\n",
        "\n",
        "- Works only on Series (one-dimensional).\n",
        "\n",
        "- Applies a function, dictionary, or mapping to each element in the Series.\n",
        "\n",
        "- Element-wise operation.\n",
        "\n",
        "**EXAMPLE:**\n",
        "\n"
      ],
      "metadata": {
        "id": "BDtclTaSdla2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "s = pd.Series([1, 2, 3, 4])\n",
        "\n",
        "# Using a function\n",
        "print(s.map(lambda x: x**2))\n",
        "\n",
        "# Using a dictionary\n",
        "print(s.map({1: 'A', 2: 'B'}))\n",
        "\n",
        "# Using a function on strings\n",
        "s2 = pd.Series(['cat', 'dog', 'bat'])\n",
        "print(s2.map(str.upper))"
      ],
      "metadata": {
        "id": "k879gzxcd0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 2. apply()**\n",
        "\n",
        "- Works on both Series and DataFrame.\n",
        "\n",
        "- On a Series ‚Üí similar to map(), applies a function element-wise.\n",
        "\n",
        "- On a DataFrame ‚Üí applies a function along an axis (rows or columns).\n",
        "\n",
        "- axis=0 ‚Üí function applied column-wise\n",
        "\n",
        "- axis=1 ‚Üí function applied row-wise\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "MlMVQn0dd6t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [10, 20, 30]\n",
        "})\n",
        "\n",
        "# Apply on Series\n",
        "print(df['A'].apply(lambda x: x**2))\n",
        "\n",
        "# Apply on DataFrame (column-wise sum)\n",
        "print(df.apply(sum, axis=0))\n",
        "\n",
        "# Apply on DataFrame (row-wise sum)\n",
        "print(df.apply(sum, axis=1))"
      ],
      "metadata": {
        "id": "1AsRpiN_eFdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18.What are some advanced features of NumPy?**\n",
        "\n",
        "NumPy isn‚Äôt just about arrays and basic math ‚Äî it has advanced features that make it powerful for scientific computing, machine learning, and data processing. Here are some of the most important ones:\n",
        "\n",
        "**1. Broadcasting**\n",
        "- Allows arithmetic operations between arrays of different shapes without explicit looping.\n",
        "\n",
        "**2. Vectorization**\n",
        "\n",
        "- Replaces Python loops with fast, low-level C implementations.\n",
        "\n",
        "- Makes operations much faster than using for loops."
      ],
      "metadata": {
        "id": "RnbR0AL-eLvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "print(arr[[0, 3]])          # Fancy indexing ‚Üí [10 40]\n",
        "print(arr[arr > 25])        # Boolean indexing ‚Üí [30 40 50]"
      ],
      "metadata": {
        "id": "VtpSyX4Kefet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Fancy Indexing & Boolean Indexing**\n",
        "- Select elements using arrays of indices or conditions.\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "QxGgP9FkekFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "print(arr[[0, 3]])          # Fancy indexing ‚Üí [10 40]\n",
        "print(arr[arr > 25])        # Boolean indexing ‚Üí [30 40 50]"
      ],
      "metadata": {
        "id": "Ks6Kwc6ieuKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Structured Arrays & Record Arrays**\n",
        "\n",
        "- Store heterogeneous data (like tables) in a single NumPy array.\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "f60Gkr5EgA5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([(1, 'Alice', 3.5),\n",
        "                 (2, 'Bob', 7.2)],\n",
        "                dtype=[('id', 'i4'), ('name', 'U10'), ('score', 'f4')])\n",
        "print(data['name'])"
      ],
      "metadata": {
        "id": "77kU60E-gCe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **5. Universal Functions** (ufuncs)\n",
        "\n",
        "- Highly optimized element-wise functions (e.g., np.sin, np.exp, np.add).\n",
        "\n",
        "- Support broadcasting and can be combined with reduce, accumulate, outer.\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "9xaIhBGpgHOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3])\n",
        "print(np.add.reduce(x))  # sum ‚Üí 6"
      ],
      "metadata": {
        "id": "giG4O9mbgL1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19.How does Pandas simplify time series analysis?**\n",
        "Pandas was originally built with time **series analysis in mind**, so it provides a lot of **tools** that make working with dates, times, and indexed data much simpler compared to plain Python.\n",
        "\n",
        "**1. Date and Time Indexing**\n",
        "\n",
        "- Pandas has a special DatetimeIndex that lets you use dates and times as the index.\n",
        "\n",
        "- This allows label-based indexing with time stamps."
      ],
      "metadata": {
        "id": "LD1tV4eGgPRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a time series\n",
        "dates = pd.date_range(\"2025-01-01\", periods=5, freq=\"D\")\n",
        "ts = pd.Series([10, 20, 30, 40, 50], index=dates)\n",
        "\n",
        "print(ts[\"2025-01-03\"])   # Access by date ‚Üí 30\n",
        "print(ts[\"2025-01\"])      # Slice by month"
      ],
      "metadata": {
        "id": "e01R3LPXgywV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Resampling and Frequency Conversion**\n",
        "\n",
        "- Easily convert data between frequencies (e.g., daily ‚Üí monthly, hourly ‚Üí daily).\n",
        "\n",
        "- Supports aggregation (mean, sum, etc.) and upsampling/downsampling.\n",
        "\n",
        "\n",
        "print(ts.resample(\"M\").mean())  # Monthly average\n",
        "\n",
        "\n",
        "**3. Shifting and Lagging**\n",
        "\n",
        "- You can shift data forward or backward in time to calculate changes, returns, etc.\n"
      ],
      "metadata": {
        "id": "TU-Rsrs0g_Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ts.shift(1))    # Lagged values\n",
        "print(ts.diff())      # First difference\n"
      ],
      "metadata": {
        "id": "R-W3jwwrh1Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **4. Rolling, Expanding, and Moving Windows**\n",
        "\n",
        "- Built-in support for rolling statistics, moving averages, expanding windows.\n"
      ],
      "metadata": {
        "id": "FjZ2dsfZh2db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ts.rolling(window=3).mean())  # 3-day moving average"
      ],
      "metadata": {
        "id": "iigu9WASh7Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Time Zone Handling**\n",
        "\n",
        "- Pandas supports time zone‚Äìaware DatetimeIndex objects and conversion."
      ],
      "metadata": {
        "id": "MKok7dSLh_O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_utc = ts.tz_localize(\"UTC\")\n",
        "print(ts_utc.tz_convert(\"Asia/Kolkata\"))"
      ],
      "metadata": {
        "id": "zHY9XsjMiHIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20.What is the role of a pivot table in Pandas?**\n",
        "\n",
        "In Pandas, a pivot table plays the role of a powerful tool for summarizing, aggregating, and reorganizing data ‚Äî very similar to pivot tables in Excel.\n",
        "\n",
        " **Role of a Pivot Table in Pandas**\n",
        "\n",
        "**1.Data Summarization**\n",
        "\n",
        "- Pivot tables group data by one or more keys (rows/columns) and apply an aggregation function (like mean, sum, count, etc.).\n",
        "\n",
        "- This helps in quickly getting insights from large datasets.\n",
        "\n",
        "**2.Reshaping Data**\n",
        "\n",
        "- Transforms data from long format to wide format.\n",
        "\n",
        "- Useful for cross-tabulations and comparisons between categories.\n",
        "\n",
        "**3.Aggregation and Statistics**\n",
        "\n",
        "- Supports multiple aggregation functions (mean, sum, min, max, count).\n",
        "\n",
        "- Can show multiple aggregations at once.\n",
        "\n",
        "**4.Multi-level Grouping**\n",
        "\n",
        "- Allows grouping by multiple columns (hierarchical indexing).\n",
        "\n",
        "- Helps analyze data across several dimensions.\n",
        "\n",
        "\n",
        "**EXAMPLE**:\n"
      ],
      "metadata": {
        "id": "shVV9eHTiK5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Department': ['Sales', 'Sales', 'HR', 'HR', 'IT', 'IT'],\n",
        "    'Employee': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
        "    'Salary': [5000, 6000, 4500, 4800, 7000, 7200],\n",
        "    'Bonus': [500, 600, 300, 400, 800, 900]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a pivot table\n",
        "pivot = pd.pivot_table(df,\n",
        "                       values=['Salary', 'Bonus'],\n",
        "                       index='Department',\n",
        "                       aggfunc={'Salary': 'mean', 'Bonus': 'sum'})\n",
        "\n",
        "print(pivot)"
      ],
      "metadata": {
        "id": "sEm1aWKIiXaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21.Why is NumPy‚Äôs array slicing faster than Python‚Äôs list slicing?**\n",
        "\n",
        "NumPy‚Äôs array slicing is much faster than **Python‚Äôs built-in list slicing**, and the main reasons come from how they are implemented under the hood.\n",
        "\n",
        "üîπ **1. Memory Layout**\n",
        "\n",
        "- **Python lists:**\n",
        "\n",
        "- A list is an array of **pointers to objects scattered** in memory.\n",
        "\n",
        "- **Slicing a list creates** a new list with copies of references (extra overhead).\n",
        "\n",
        "- **NumPy arrays:**\n",
        "\n",
        "- Stored as a **contiguous block of memory** (like a C array).\n",
        "\n",
        "- Slicing does not **copy data; instead, it creates a view into the same memory buffer using strides**.\n",
        "\n",
        "- This makes slicing constant-time (no data copying).\n",
        "\n",
        "üîπ **2. Views vs Copies**\n",
        "\n",
        "- **Python list slicing ‚Üí** Always makes a new object (copy of references).\n",
        "\n",
        "- **NumPy array slicing ‚Üí** Returns a view (unless explicitly copied).\n",
        "\n"
      ],
      "metadata": {
        "id": "Va5PShcKigr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.arange(10)\n",
        "slice_arr = arr[2:6]   # view, no data copied\n",
        "slice_arr[0] = 99\n",
        "print(arr)             # original array also changes"
      ],
      "metadata": {
        "id": "3FHUPEaNiriA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Vectorized Implementation**\n",
        "\n",
        "- NumPy is built on C and Fortran libraries (BLAS/LAPACK).\n",
        "\n",
        "- Slicing just adjusts pointers and strides instead of looping over elements.\n",
        "\n",
        "- Python **lists, being high-level,** need to loop element by element in pure Python ‚Üí slower.\n",
        "\n",
        " **4. Data Type Uniformity**\n",
        "\n",
        "- NumPy arrays have a single data type (dtype), which allows efficient pointer arithmetic.\n",
        "\n",
        "- Python lists can contain mixed types, so slicing needs type checks and extra overhead."
      ],
      "metadata": {
        "id": "UYI__YJ4iwPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22.What are some common use cases for Seaborn?**\n",
        "\n",
        "**Seaborn is a Python data visualization library** built on top of Matplotlib, designed for making statistical **graphics easier and prettier**. It‚Äôs widely used in data analysis and machine learning workflows.\n",
        "\n",
        " **1. Exploratory Data Analysis** (EDA)\n",
        "\n",
        "- Quickly understand **distributions, relationships, and patterns** in datasets.\n",
        "\n",
        "- **Example:** visualizing the spread of numerical variables or comparing categories.\n",
        "\n",
        " **2. Visualizing Distributions**\n",
        "\n",
        "- Functions like histplot(), kdeplot(), distplot() (deprecated) show probability distributions.\n",
        "\n",
        "- Useful for detecting skewness, outliers, and spread of data.\n"
      ],
      "metadata": {
        "id": "MKu6PurEi5de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(data=[1,2,2,3,3,3,4,4,5], kde=True)"
      ],
      "metadata": {
        "id": "Ng8uIy37jP9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **3. Comparing Categories**\n",
        "\n",
        "- Bar plots, count plots, and box plots for categorical data analysis.\n",
        "\n",
        "- Great for understanding differences between groups\n",
        "\n",
        "sns.boxplot(x=\"species\", y=\"sepal_length\", data=sns.load_dataset(\"iris\"))\n",
        "\n",
        "\n",
        "**4. Relationship Analysis**\n",
        "\n",
        "- Scatter plots, regression lines (lmplot, regplot) to analyze correlation between variables.\n",
        "\n",
        "sns.lmplot(x=\"sepal_length\", y=\"petal_length\", data=sns.load_dataset(\"iris\"))\n",
        "\n",
        "\n",
        "**5. Heatmaps & Correlation Analysis**\n",
        "\n",
        "- heatmap() is often used to visualize correlation matrices in feature analysis\n"
      ],
      "metadata": {
        "id": "iwf921VqjTtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "# Drop the non-numerical 'species' column before calculating correlation\n",
        "sns.heatmap(iris.drop('species', axis=1).corr(), annot=True, cmap=\"coolwarm\")"
      ],
      "metadata": {
        "id": "yFBn10MfjeJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL"
      ],
      "metadata": {
        "id": "bQVVw3pdjjco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "**Q1.How do you create a 2D NumPy array and calculate the sum of each row?**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a 2D NumPy array\n",
        "array_2d = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6],\n",
        "                     [7, 8, 9]])\n",
        "\n",
        "print(\"2D NumPy Array:\")\n",
        "print(array_2d)\n",
        "\n",
        "# Calculate the sum of each row\n",
        "# The axis=1 argument specifies that the sum should be calculated across columns (for each row)\n",
        "row_sums = np.sum(array_2d, axis=1)\n",
        "\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n"
      ],
      "metadata": {
        "id": "qJLo9BLJjmGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q2.Write a Pandas script to find the mean of a specific column in a DataFrame?**\n",
        "\n",
        "# Find the mean of a specific column (e.g., 'Salary')\n",
        "mean_salary = df['Salary'].mean()\n",
        "\n",
        "print(f\"The mean salary is: {mean_salary}\")"
      ],
      "metadata": {
        "id": "H6QUTi_Qj9Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q3.Create a scatter plot using Matplotlib?**\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Often used with matplotlib for datasets and styling\n",
        "\n",
        "# Load the iris dataset if not already loaded (though it is in this notebook)\n",
        "# iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6)) # Optional: set figure size\n",
        "plt.scatter(iris['sepal_length'], iris['sepal_width'], alpha=0.7) # alpha for transparency\n",
        "plt.title('Scatter Plot of Sepal Length vs Sepal Width (Iris Dataset)')\n",
        "plt.xlabel('Sepal Length (cm)')\n",
        "plt.ylabel('Sepal Width (cm)')\n",
        "plt.grid(True) # Optional: add a grid\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "enUjcsRJjwA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q4.How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?**\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the iris dataset (if not already loaded)\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Calculate the correlation matrix, excluding the non-numerical 'species' column\n",
        "correlation_matrix = iris.drop('species', axis=1).corr()\n",
        "\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6)) # Optional: set figure size\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\") # annot shows values, fmt formats them\n",
        "plt.title('Correlation Heatmap of Iris Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iYexu9UfkG6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q5.Generate a bar plot using Plotly?**\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Use the 'pivot' DataFrame created earlier for department-wise sums\n",
        "# Or use the original df and group by department to calculate the sum\n",
        "# Here, I'll use the original df and group by department to get the sum of salaries\n",
        "department_salary_sum = df.groupby('Department')['Salary'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot using Plotly Express\n",
        "fig = px.bar(department_salary_sum,\n",
        "             x='Department',\n",
        "             y='Salary',\n",
        "             title='Total Salary by Department')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-M1KvJiQkl-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q6.Create a DataFrame and add a new column based on an existing column?**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'Numbers': [1, 2, 3, 4, 5]}\n",
        "df_new = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df_new)\n",
        "\n",
        "# Add a new column 'Squared' based on the 'Numbers' column\n",
        "df_new['Squared'] = df_new['Numbers'] ** 2\n",
        "\n",
        "print(\"\\nDataFrame with new column:\")\n",
        "print(df_new)\n"
      ],
      "metadata": {
        "id": "69-dku0uk4KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q7.Write a program to perform element-wise multiplication of two NumPy arrays?**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two NumPy arrays\n",
        "array1 = np.array([[1, 2],\n",
        "                   [3, 4]])\n",
        "\n",
        "array2 = np.array([[5, 6],\n",
        "                   [7, 8]])\n",
        "\n",
        "print(\"Array 1:\")\n",
        "print(array1)\n",
        "\n",
        "print(\"\\nArray 2:\")\n",
        "print(array2)\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result_array = array1 * array2\n",
        "\n",
        "print(\"\\nResult of element-wise multiplication:\")\n",
        "print(result_array)"
      ],
      "metadata": {
        "id": "8hXK674MlA7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q8.Create a line plot with multiple lines using Matplotlib?**\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y1 = np.array([2, 4, 6, 8, 10])\n",
        "y2 = np.array([1, 3, 5, 7, 9])\n",
        "y3 = np.array([5, 2, 8, 3, 7])\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6)) # Optional: set figure size\n",
        "\n",
        "plt.plot(x, y1, marker='o', linestyle='-', color='blue', label='Line 1')\n",
        "plt.plot(x, y2, marker='x', linestyle='--', color='red', label='Line 2')\n",
        "plt.plot(x, y3, marker='s', linestyle='-.', color='green', label='Line 3')\n",
        "\n",
        "plt.title('Line Plot with Multiple Lines')\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.legend() # Show the legend to identify lines\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0RwLivs1lI85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q9.A Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold?**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Numbers': [10, 25, 5, 40, 15, 30]}\n",
        "df_filter = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df_filter)\n",
        "\n",
        "# Define a threshold\n",
        "threshold = 20\n",
        "\n",
        "# Filter rows where the 'Numbers' column is greater than the threshold\n",
        "filtered_df = df_filter[df_filter['Numbers'] > threshold]\n",
        "\n",
        "print(f\"\\nDataFrame filtered for 'Numbers' > {threshold}:\")\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "dWXYK80JlbfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q10.Create a histogram using Seaborn to visualize a distribution?\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create some sample data for the histogram\n",
        "data_for_histogram = [1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 5, 6, 6, 7]\n",
        "\n",
        "# Create the histogram using Seaborn's histplot\n",
        "plt.figure(figsize=(8, 6)) # Optional: set figure size\n",
        "sns.histplot(data=data_for_histogram, kde=True) # kde=True adds a kernel density estimate line\n",
        "plt.title('Distribution of Sample Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HB0kXAlnlh0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q11.Perform matrix multiplication using NumPy?**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two NumPy matrices (2D arrays)\n",
        "matrix1 = np.array([[1, 2],\n",
        "                    [3, 4]])\n",
        "\n",
        "matrix2 = np.array([[5, 6],\n",
        "                    [7, 8]])\n",
        "\n",
        "print(\"Matrix 1:\")\n",
        "print(matrix1)\n",
        "\n",
        "print(\"\\nMatrix 2:\")\n",
        "print(matrix2)\n",
        "\n",
        "# Perform matrix multiplication using the @ operator (preferred in Python 3.5+)\n",
        "result_matrix = matrix1 @ matrix2\n",
        "\n",
        "# Alternatively, using np.dot()\n",
        "# result_matrix = np.dot(matrix1, matrix2)\n",
        "\n",
        "print(\"\\nResult of matrix multiplication:\")\n",
        "print(result_matrix)\n"
      ],
      "metadata": {
        "id": "g6mdriIol5r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q12.Use Pandas to load a CSV file and display its first 5 rows?**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'sample.csv' with the actual path to your CSV file\n",
        "try:\n",
        "    df_csv = pd.read_csv('sample.csv')\n",
        "\n",
        "    print(\"DataFrame loaded from CSV:\")\n",
        "    # Display the first 5 rows\n",
        "    display(df_csv.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'sample.csv' not found. Please replace 'sample.csv' with the correct path to your file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "-cBSZctfl_CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q13.Create a 3D scatter plot using Plotly?**\n",
        "\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the iris dataset if not already loaded\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = px.scatter_3d(iris,\n",
        "                    x='sepal_length',\n",
        "                    y='sepal_width',\n",
        "                    z='petal_length',\n",
        "                    color='species',\n",
        "                    title='3D Scatter Plot of Iris Dataset')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "w9p_0catmNLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}