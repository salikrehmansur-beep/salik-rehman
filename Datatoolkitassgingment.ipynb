{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DATA TOOLKIT"
      ],
      "metadata": {
        "id": "VnhHa5gBz8VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.What is NumPy, and why is it widely used in Python?**\n",
        "\n",
        "NumPy (short for Numerical Python) is a **powerful open-source library** in Python used for numerical computing. It provides tools for working with large, multi-dimensional arrays and matrices, along with a wide **collection of high-level mathematical functions** to operate on these arrays efficiently.\n",
        "\n",
        "- A **Python library** that adds support for n-dimensional arrays (called ndarray).\n",
        "\n",
        "- Provides **vectorized operations**, meaning operations are applied on whole arrays at once (instead of element by element).\n",
        "\n",
        "- Written in C and optimized for speed, making it much faster than using plain Python lists for **numerical tasks**.\n",
        "\n",
        "**ðŸ”¹ Why NumPy is widely used:**\n",
        " **1.Efficient array operations**\n",
        "\n",
        "- NumPy arrays use less memory and are faster than Python lists.\n",
        "\n",
        "- Example: Multiplying two arrays with * in NumPy is element-wise and optimized.\n",
        "\n",
        "**2.Mathematical functions**\n",
        "\n",
        "- Provides functions for linear algebra, statistics, Fourier transforms, random number generation, etc.\n",
        "\n",
        "**3.Integration with other libraries**\n",
        "\n",
        "- Core dependency for **pandas, scikit-learn, TensorFlow, PyTorch, Matplotlib, and many more**.\n",
        "\n",
        "- Acts as the foundation of the **scientific Python ecosystem**.\n",
        "\n",
        "**4.Convenient slicing and indexing**\n",
        "\n",
        "- More powerful than **Python lists** (supports multi-dimensional slicing, boolean indexing, fancy indexing).\n",
        "\n",
        "**5.Broadcasting**\n",
        "\n",
        "- Allows **operations between arrays of different shapes** without explicitly writing loops.\n",
        "\n",
        "**6.Cross-platform**\n",
        "\n",
        "- Works across different **operating systems and hardware** (including GPU acceleration through libraries like CuPy).\n"
      ],
      "metadata": {
        "id": "hOwrXs2Ez-8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.How does broadcasting work in NumPy?**\n",
        "\n",
        "**Broadcasting** is a set of rules that NumPy follows when performing **arithmetic operations on arrays** with different shapes.\n",
        "\n",
        "Instead of requiring arrays to be the exact same shape, NumPy tries to â€œstretchâ€ the **smaller array across the larger one so that element-wise*** operations are possible without actually copying data.\n",
        "\n",
        "**ðŸ”¹ Rules of Broadcasting**\n",
        "- Compare their shapes from right to left.\n",
        "\n",
        "- Dimensions are compatible if:\n",
        "\n",
        "**They are equal, or** **One of them is 1**.\n",
        "\n",
        "- If one array has fewer dimensions, NumPy adds leading 1s to make the shapes match.\n",
        "\n",
        "- If dimensions are still incompatible, NumPy raises an error.\n"
      ],
      "metadata": {
        "id": "_ZEXfBF70e84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.What is a Pandas DataFrame?**\n",
        "\n",
        "A **Pandas DataFrame** is a **two-dimensional, tabular data structure** in the **pandas library** (built on top of NumPy).\n",
        "\n",
        "It is like a **spreadsheet or SQL table in Python** â€” with rows and columns, where:\n",
        "\n",
        "- **ROWS â†’** represent observations/records\n",
        "\n",
        "- **COLUMNS â†’** represent features/attributes\n",
        "\n",
        "Each column can hold different data types (integer, float, string, datetime, etc.)\n",
        "\n",
        "ðŸ”¹ **KEY FEATURE OF DATAFRAME**\n",
        "- **1.Labeled axes â†’** Rows (index) and Columns (column names).\n",
        "\n",
        "- **2.Heterogeneous data â†’** Different data types in different columns.\n",
        "\n",
        "- **3.Size mutable â†’** Can add or drop rows/columns.\n",
        "\n",
        "- **4.Data alignment â†’** Handles missing data gracefully (NaN).\n",
        "\n",
        "- **5.Built-in methods â†’** For filtering, grouping, aggregation, merging, reshaping, etc.\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "8BbP--aW4gBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from a dictionary\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"Age\": [25, 30, 35],\n",
        "    \"City\": [\"New York\", \"London\", \"Paris\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "1eueOZ2R7Lle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.Explain the use of the groupby() method in Pandas?**\n",
        "\n",
        "The groupby() method in Pandas is used to **split data into groups** based on the values in one or more columns, and then apply **aggregation, transformation, or filtering operations** on those groups.\n",
        "\n",
        "It follows the â€œ**split â†’ apply â†’ combine**â€ process:\n",
        "\n",
        "- **1.Split** â€“ Divide the data into groups (by column values).\n",
        "\n",
        "- **2.Apply** â€“ Apply a function (like sum, mean, count, etc.) to each group.\n",
        "\n",
        "- **3.Combine** â€“ Merge the results back into a DataFrame.\n",
        "\n",
        "**SYNTAX:**\n",
        "\n",
        "df.groupby('column_name')\n",
        "\n",
        "df.groupby(['col1', 'col2'])\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "bHSp5RAm7NTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Department\": [\"HR\", \"HR\", \"IT\", \"IT\", \"Finance\"],\n",
        "    \"Employee\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"],\n",
        "    \"Salary\": [50000, 55000, 60000, 65000, 70000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Group by Department and calculate average salary\n",
        "result = df.groupby(\"Department\")[\"Salary\"].mean()\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "eVE8dgyU7WeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.Why is Seaborn preferred for statistical visualizations?**\n",
        "\n",
        "**Seaborn is a Python data visualization** library built on top of Matplotlib.\n",
        "It is preferred for **statistical visualizations because it provides a high-level, easy-to-use interface and comes with built-in support** for statistical plots.\n",
        "\n",
        "- **KEY REASON SEABORN IS PREPARERD:**\n",
        "\n",
        "**1.Simpler Syntax & High-Level API**\n",
        "\n",
        "- Seaborn lets you create complex statistical plots with just one line of code, whereas **Matplotlib** often requires many lines.\n",
        "\n",
        "**2.Beautiful Default Styles**\n",
        "\n",
        "- **Seaborn** has attractive, **modern default themes that make plots** look professional without extra formatting.\n",
        "\n",
        "**3.Built-in Statistical Functions**\n",
        "\n",
        "- Automatically handles statistical **estimation and visualization (e.g., confidence intervals**, regression lines).\n",
        "\n",
        "- **Example**: sns.regplot() adds regression line + confidence interval automatically.\n",
        "\n",
        "**4.ntegration with Pandas DataFrames**\n",
        "\n",
        "- Works directly with Pandas DataFrames and column names, reducing the need for manual indexing.\n",
        "\n",
        "**5.Specialized Statistical Plots**\n",
        "\n",
        "- Provides advanced plots that Matplotlib doesnâ€™t have out-of-the-box, like:\n",
        "\n",
        "- Heatmaps (sns.heatmap)\n",
        "\n",
        "- Pair plots (sns.pairplot)\n",
        "\n",
        "- Violin plots (sns.violinplot)\n",
        "\n",
        "- Distribution plots (sns.histplot, sns.kdeplot)\n",
        "\n",
        "**6.Automatic Handling of Categorical Data**\n",
        "\n",
        "- Seaborn makes it easy to **compare categories visually** (bar plots, box plots, swarm plots, etc.).\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "155Kdwg57cNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(df[\"Salary\"], bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.xlabel(\"Salary\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Salary Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KbYDybP673Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Differences Between NumPy Arrays and Python Lists:**\n",
        "\n",
        "\n",
        "| Feature                     | **Python List**                                                              | **NumPy Array (`ndarray`)**                                                  |\n",
        "| --------------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------- |\n",
        "| **Data Type**               | Can store **heterogeneous data** (int, float, string, etc.) in the same list | Stores **homogeneous data** (all elements must be of the same type)          |\n",
        "| **Memory Usage**            | Stores data as **objects**, so it is less memory-efficient                   | Stores data in **contiguous blocks** of memory â†’ more efficient              |\n",
        "| **Performance**             | Slower for numerical operations (uses Python loops)                          | Much faster (vectorized operations implemented in C)                         |\n",
        "| **Functionality**           | Only basic operations (append, pop, slicing)                                 | Supports advanced mathematical, linear algebra, statistical operations       |\n",
        "| **Dimension Support**       | 1D only (list of lists for 2D, but clunky)                                   | Supports **n-dimensional arrays** (matrix, tensor, etc.)                     |\n",
        "| **Broadcasting**            | Not supported                                                                | Fully supports **broadcasting** (operations on arrays of different shapes)   |\n",
        "| **Element-wise Operations** | Must use loops or list comprehensions                                        | Directly supports element-wise operations (e.g., `a + b`)                    |\n",
        "| **Integration**             | General-purpose                                                              | Backbone for data science libraries (Pandas, Scikit-learn, TensorFlow, etc.) |\n",
        "\n",
        "**EXAMPLE**"
      ],
      "metadata": {
        "id": "FmFtEOC88NyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [1, 2, 3, 4]\n",
        "result = [x*2 for x in lst]\n",
        "print(result)\n",
        "\n",
        "\n",
        "- **NUMPY ARRAY**\n",
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "result = arr * 2\n",
        "print(result)"
      ],
      "metadata": {
        "id": "oHzJXPgp8SSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.What is a heatmap, and when should it be used?**\n",
        "\n",
        "A **heatmap is a data visualization technique** that uses color shading to represent values in a 2D matrix or table.\n",
        "\n",
        "- Each cell in the table is *colored** based on its value.\n",
        "\n",
        "- **Darker or brighter colors** usually represent higher or lower values (depending on the color scale).\n",
        "\n",
        "In Python, heatmaps are commonly created with **Seaborn (sns.heatmap) or Matplotlib.**\n",
        "\n",
        "**EXAMPLE**"
      ],
      "metadata": {
        "id": "jgBNRx2R8X5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "data = np.array([[1, 2, 3],\n",
        "                 [4, 5, 6],\n",
        "                 [7, 8, 9]])\n",
        "\n",
        "sns.heatmap(data, annot=True, cmap=\"coolwarm\")\n",
        "plt.show()\n",
        "\n",
        "ðŸ”¹ **When Should a Heatmap Be Used**:"
      ],
      "metadata": {
        "id": "MQ3x7fd3BMZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **When Should a Heatmap Be Used**:\n",
        "\n",
        "**1.Correlation Analysis**\n",
        "\n",
        "- To show relationships between variables in a dataset.\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"viridis\")\n",
        "\n",
        "**2.Visualizing Matrices**\n",
        "\n",
        "- Great for showing confusion matrices in machine learning.\n",
        "\n",
        "**3.Highlighting Patterns**\n",
        "\n",
        "- Easy to spot trends, clusters, or anomalies in data (e.g., sales over time, temperature variations).\n",
        "\n",
        "**4.Comparisons in Large Data**\n",
        "\n",
        "- Makes large numeric datasets easier to interpret visually."
      ],
      "metadata": {
        "id": "4geYlMiDBcvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. What does the term â€œvectorized operationâ€ mean in NumPy?**\n",
        "\n",
        "A vectorized operation means **performing an operation** on an entire array (or batch of data) at once, without writing explicit **Python loops**.\n",
        "\n",
        "- NumPy implements these operations in **optimized C code** under the hood.\n",
        "\n",
        "- This makes them much faster and more concise than looping through elements in **pure Python.**\n",
        "\n",
        "ðŸ”¹ **EXAMPLE**\n",
        "\n",
        "âŒ **Without Vectorization** (using a loop)"
      ],
      "metadata": {
        "id": "rP1RdqvsCDh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = [1, 2, 3, 4]\n",
        "result = []\n",
        "for n in numbers:\n",
        "    result.append(n * 2)\n",
        "\n",
        "print(result)  # [2, 4, 6, 8]\n",
        "\n",
        "#%% md\n",
        "âœ… **With Vectorization** (NumPy)\n",
        "#%%\n",
        "import numpy as np\n",
        "\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "result = arr * 2\n",
        "\n",
        "print(result)  # [2 4 6 8]"
      ],
      "metadata": {
        "id": "monTU578CL-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Why Vectorized Operations are Important**\n",
        "- **1.Speed â†’** Runs in C (much faster than Python loops).\n",
        "\n",
        "- **2.Simplicity â†’** Cleaner, more readable code.\n",
        "\n",
        "- **3.Memory Efficiency â†’** No need for intermediate lists.\n",
        "\n",
        "- **4.Mathematical Expressiveness â†’** Code looks like real math equations."
      ],
      "metadata": {
        "id": "23Rp604sCWB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.How does Matplotlib differ from Plotly?**\n",
        "\n",
        "- ðŸ”¹ **KEY DIFFERENCES BETWEEN MATPLOTLIB & PLOTLY**\n",
        "\n",
        "| Feature           | **Matplotlib**                                                                    | **Plotly**                                                            |\n",
        "| ----------------- | --------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
        "| **Type**          | Low-level, static plotting library                                                | High-level, interactive plotting library                              |\n",
        "| **Interactivity** | Mostly static (can use `mpl_interactions` or `%matplotlib notebook`, but limited) | Fully interactive (zoom, pan, hover tooltips, clickable legends)      |\n",
        "| **Ease of Use**   | Requires more code for styling and customization                                  | Easier for interactive dashboards and quick interactive plots         |\n",
        "| **Customization** | Very flexible, but verbose                                                        | Limited compared to Matplotlib, but sufficient for most               |\n",
        "| **Integration**   | Works well with Pandas, NumPy, Seaborn                                            | Works with Pandas, NumPy, Dash (for web apps)                         |\n",
        "| **Output**        | Best for static plots (PDFs, PNGs, scientific papers)                             | Best for interactive visualizations (web, dashboards)                 |\n",
        "| **Performance**   | Handles large datasets efficiently                                                | Can be slower for very large datasets (due to interactivity overhead) |\n",
        "| **3D Support**    | Basic 3D plotting (`mpl_toolkits.mplot3d`)                                        | Strong 3D plotting (interactive 3D scatter, surface, mesh)            |\n",
        "\n",
        "**EXAMPLE**\n",
        "- **Matplotlib** (Static Plot)"
      ],
      "metadata": {
        "id": "jPeIwCm5CZpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [1, 2, 3, 4]\n",
        "y = [10, 20, 25, 30]\n",
        "\n",
        "plt.plot(x, y, marker=\"o\")\n",
        "plt.title(\"Matplotlib Example\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.show()\n",
        "\n",
        "**Plotly** (Interactive Plot)\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "x = [1, 2, 3, 4]\n",
        "y = [10, 20, 25, 30]\n",
        "\n",
        "fig = px.line(x=x, y=y, markers=True, title=\"Plotly Example\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bW3oMlkUCzQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.What is the significance of hierarchical indexing in Pandas?**\n",
        "\n",
        "**Hierarchical indexing** (also called a MultiIndex) in Pandas allows you to have multiple levels of row or column indexes in a DataFrame or Series.\n",
        "\n",
        "Instead of just one row label, you can use two or more indexes, which creates a tree-like structure.\n",
        "\n",
        "**Why is it Significant**:\n",
        "\n",
        " **1.Represents Higher-Dimensional Data in 2D**\n",
        "\n",
        "- Lets you work with higher-dimensional data (like 3D or 4D) in a 2D DataFrame format.\n",
        "\n",
        "**2.More Powerful Data Selection**:\n",
        "\n",
        "- You can access data using multiple keys (e.g., df.loc[('India', 'Delhi')]).\n",
        "\n",
        "**3.Better Data Organization**:\n",
        "\n",
        "- Useful for grouping and working with datasets that have natural hierarchical structures (e.g., Country â†’ State â†’ City).\n",
        "\n",
        "**4.Works Seamlessly with GroupBy**\n",
        "\n",
        "- Many groupby() operations return results with a MultiIndex.\n"
      ],
      "metadata": {
        "id": "p_mv_oUMC9wY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.What is the role of Seabornâ€™s pairplot() function?**\n",
        "\n",
        "Seabornâ€™s pairplot() is a **high-level visualization tool used to quickly explore the relationships between multiple variables in a dataset**.\n",
        "\n",
        "It creates a matrix of plots:\n",
        "\n",
        "- **Diagonal â†’** Distribution of each variable (histogram or KDE).\n",
        "\n",
        "- **Off-diagonal â†’** Scatter plots showing relationships between pairs of variables.\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "vOtW5S_mDFMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load example dataset\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Pairplot with hue for species\n",
        "sns.pairplot(iris, hue=\"species\", diag_kind=\"kde\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RJfP8PDnDJgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.What is the purpose of the describe() function in Pandas?**\n",
        "\n",
        "The describe() function in **Pandas is used to generate summary statistics** of a DataFrame (or Series).\n",
        "It gives you a quick overview of the distribution and key statistics of your data.\n",
        "\n",
        "ðŸ”¹ **What It Returns**\n",
        "\n",
        "By default (for numerical columns), it provides:\n",
        "\n",
        "- **count â†’** Number of non-null values\n",
        "\n",
        "- **mean â†’** Average value\n",
        "\n",
        "- **std â†’** Standard deviation (spread of values)\n",
        "\n",
        "- **min â†’** Minimum value\n",
        "\n",
        "- **25% â†’** First quartile (Q1)\n",
        "\n",
        "- **50% â†’** Median (Q2)\n",
        "\n",
        "- **75% â†’** Third quartile (Q3)\n",
        "\n",
        "- **max â†’** Maximum value\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "766lkqukDiA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Age\": [22, 25, 29, 30, 32, 35],\n",
        "    \"Salary\": [30000, 35000, 40000, 42000, 50000, 60000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "DqxEkdsJDkjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. Why is handling missing data important in Pandas?**\n",
        "\n",
        "**1.Maintains Data Quality**\n",
        "\n",
        "- Missing values can reduce the **reliability and accuracy** of your analysis.\n",
        "\n",
        "- For example, calculating an **Avarage** salary with missing entries might give misleading results.\n",
        "\n",
        "**2.Prevents Errors in Analysis**\n",
        "\n",
        "- Many Pandas/NumPy functions (like mean(), sum(), corr()) may return NaN if missing values are not handled.\n",
        "\n",
        "- Machine learning models (like in scikit-learn) often cannot handle missing values directly.\n",
        "\n",
        "**3.Preserves Statistical Validity**\n",
        "\n",
        "- Missing data can bias results if not **treated properly**.\n",
        "\n",
        "- **Example:** If younger peopleâ€™s ages are missing, the average age will be incorrectly higher.\n",
        "\n",
        "**4.Enables Better Modeling**\n",
        "\n",
        "- Models require complete, **clean data** to learn patterns correctly.\n",
        "\n",
        "- Handling missing **data ensures models** donâ€™t fail or produce incorrect predictions.\n",
        "\n",
        "**5.Improves Decision-Making**\n",
        "\n",
        "- Clean datasets with no **unexpected gaps** lead to better business insights and **trustworthy reports**.\n",
        "\n",
        "**How Pandas Helps Handle Missing Data**\n",
        "\n",
        "- Pandas provides built-in functions like:\n",
        "\n",
        "- df.isnull() **â†’** Detect missing values\n",
        "\n",
        "- df.dropna() **â†’** Remove missing values\n",
        "\n",
        "- df.fillna(value) **â†’** Replace missing values with a constant, mean, median, mode, etc.\n",
        "\n",
        "- df.interpolate() **â†’** Estimate missing values using interpolation\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "QSlMvLy-Do-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "        \"Age\": [25, None, 30],\n",
        "        \"Salary\": [50000, 60000, None]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(df)\n",
        "\n",
        "# Fill missing Age with mean, Salary with 0\n",
        "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
        "df[\"Salary\"].fillna(0, inplace=True)\n",
        "\n",
        "print(\"\\nAfter Handling Missing Data:\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "L5DteFIVboDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.What are the benefits of using Plotly for data visualization?**\n",
        "\n",
        "**Benefits of Using Plotly for Data Visualization**\n",
        "\n",
        "**1.Interactivity by Default**\n",
        "\n",
        "- Unlike Matplotlib/Seaborn (which are mostly static), **Plotly charts** are interactive.\n",
        "\n",
        "- Features: zoom, pan, hover **tooltips, toggle legend items**, export as images.\n",
        "\n",
        "**2.Beautiful Visuals with Minimal Code**\n",
        "\n",
        "- Provides modern, **polished plots** without much customization.\n",
        "\n",
        "- Example: px.line() creates a fully interactive line chart in one line.\n",
        "\n",
        "**3.Wide Range of Charts**\n",
        "\n",
        "- Supports simple charts (line, bar, scatter, pie) and advanced ones:\n",
        "\n",
        "- 3D scatter, surface plots\n",
        "\n",
        "- Choropleth (maps)\n",
        "\n",
        "- Time-series charts\n",
        "\n",
        "- Sankey diagrams, Treemaps, Sunbursts\n",
        "\n",
        "**4.Seamless Pandas & NumPy Integration**\n",
        "\n",
        "- Works directly with DataFrames â†’ just pass column names **instead of manually extracting arrays.**"
      ],
      "metadata": {
        "id": "u_Hm1Xymbs4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.How does NumPy handle multidimensional arrays?**\n",
        "\n",
        "**1. REPRESENTATION**\n",
        "\n",
        "A NumPy array can have any number of dimensions:\n",
        "\n",
        "- **1.1D â†’** vector ([1, 2, 3])\n",
        "\n",
        "- **2.2D â†’** matrix ([[1, 2], [3, 4]])\n",
        "\n",
        "- **3.3D â†’** tensor ([[[1,2],[3,4]], [[5,6],[7,8]]])\n",
        "\n",
        "and so onâ€¦\n",
        "\n",
        "The number of **dimensions** is called the rank of the array.\n",
        "\n",
        "Dimensions themselves are referred to as **axes**.\n",
        "\n",
        "**EXAMPLE**:\n"
      ],
      "metadata": {
        "id": "n57880u9b1LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([[1, 2, 3],\n",
        "                [4, 5, 6]])\n",
        "print(arr.ndim)  # 2D array\n",
        "print(arr.shape) # (2, 3) â†’ 2 rows, 3 columns"
      ],
      "metadata": {
        "id": "lorGISK_b6NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.SHAPE & STRIDES**\n",
        "\n",
        "- **Shape â†’** A tuple describing the size along each axis.\n",
        "\n",
        "- **Example:** a 3Ã—4Ã—2 array has shape = (3, 4, 2)\n",
        "\n",
        "- **Strides â†’** Tell NumPy how many bytes to step in each dimension when traversing.\n",
        "\n",
        "- This makes slicing and reshaping very efficient without copying data.\n",
        "\n",
        "**3.INDEXING & SLICING**\n",
        "\n",
        "- NumPy supports multidimensional indexing:\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "2QeQmHNeb-L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([[10, 20, 30],\n",
        "                [40, 50, 60]])\n",
        "print(arr[1, 2])   # 60\n",
        "print(arr[:, 1])   # [20, 50] â†’ second column"
      ],
      "metadata": {
        "id": "zz5uQmtjcWOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.VECTORIZED OPERATIONS**:\n",
        "- Operations are applied element-wise across dimensions:\n",
        "\n",
        "**EXAMPLE**"
      ],
      "metadata": {
        "id": "DryVjs9Dck_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[1, 2], [3, 4]])\n",
        "B = np.array([[10, 20], [30, 40]])\n",
        "print(A + B)  # element-wise addition"
      ],
      "metadata": {
        "id": "7OuHtX57dFzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy uses **broadcasting** rules to handle operations on arrays of different shapes.\n",
        "\n",
        "- **5.RESHAPING & TRANSPOING**\n",
        "\n",
        "- Arrays can be reshaped without changing data\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "I8tdCVUgdGvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(12).reshape(3, 4)\n",
        "print(arr.T)   # transpose (swap axes)"
      ],
      "metadata": {
        "id": "-iEJtT58dM7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16.What is the role of Bokeh in data visualization?**\n",
        " **Role of Bokeh in Data Visualization**\n",
        "\n",
        "**1.Interactive Visualizations**\n",
        "\n",
        "- Unlike static libraries (e.g., Matplotlib), Bokeh **emphasizes interactivity (zooming, panning, tooltips, filtering)**.\n",
        "\n",
        "- **Example:** hover over a point to see details, or drag to **zoom into regions**.\n",
        "\n",
        "**2.Web-Friendly Output**\n",
        "\n",
        "- Bokeh generates **visualizations that can be rendered** in browsers using HTML, JavaScript, and JSON.\n",
        "\n",
        "- It integrates seamlessly with **Flask, Django, or Jupyter Notebooks**.\n",
        "\n",
        "**3.Handling Large Datasets**\n",
        "\n",
        "- Bokeh is optimized to work with large or streaming datasets.\n",
        "\n",
        "- It can use a Bokeh server to **stream and update data** in real time.\n",
        "\n",
        "**4.High-Level Charts & Customization**\n",
        "\n",
        "- Provides **high-level charting** (bar, line, scatter, heatmaps, etc.).\n",
        "\n",
        "- Also allows low-level control to build custom, **complex dashboards**.\n",
        "\n",
        "**5.Integration with Other Tools**\n",
        "\n",
        "- Works well with **Pandas, NumPy, and Dask for data manipulation.**\n",
        "\n",
        "- Can embed plots into **web apps or dashboards** (similar to Plotly Dash).\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "LWIYIX54dZX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show\n",
        "\n",
        "# Create a simple line plot\n",
        "p = figure(title=\"Simple Line Example\", x_axis_label='x', y_axis_label='y')\n",
        "p.line([1, 2, 3, 4], [6, 7, 2, 4], line_width=2)\n",
        "\n",
        "show(p)  # Opens in a browser"
      ],
      "metadata": {
        "id": "bYPxPvnOdn_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.Explain the difference between apply() and map() in Pandas?**\n",
        "\n",
        "\n",
        "\n",
        "| Feature      | `map()`                             | `apply()`                                   |\n",
        "| ------------ | ----------------------------------- | ------------------------------------------- |\n",
        "| Works on     | **Series only**                     | **Series & DataFrame**                      |\n",
        "| Input types  | Function, dictionary, Series        | Function (any Python function, NumPy ufunc) |\n",
        "| Output       | Transformed Series                  | Series (if applied on Series) or DataFrame  |\n",
        "| Axis support | âŒ (not needed, always element-wise) | âœ… (`axis=0` for columns, `axis=1` for rows) |\n",
        "\n",
        "** 1. map()**\n",
        "\n",
        "- Works only on Series (one-dimensional).\n",
        "\n",
        "- Applies a function, dictionary, or mapping to each element in the Series.\n",
        "\n",
        "- Element-wise operation.\n",
        "\n",
        "**EXAMPLE:**\n",
        "\n"
      ],
      "metadata": {
        "id": "BDtclTaSdla2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "s = pd.Series([1, 2, 3, 4])\n",
        "\n",
        "# Using a function\n",
        "print(s.map(lambda x: x**2))\n",
        "\n",
        "# Using a dictionary\n",
        "print(s.map({1: 'A', 2: 'B'}))\n",
        "\n",
        "# Using a function on strings\n",
        "s2 = pd.Series(['cat', 'dog', 'bat'])\n",
        "print(s2.map(str.upper))"
      ],
      "metadata": {
        "id": "k879gzxcd0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 2. apply()**\n",
        "\n",
        "- Works on both Series and DataFrame.\n",
        "\n",
        "- On a Series â†’ similar to map(), applies a function element-wise.\n",
        "\n",
        "- On a DataFrame â†’ applies a function along an axis (rows or columns).\n",
        "\n",
        "- axis=0 â†’ function applied column-wise\n",
        "\n",
        "- axis=1 â†’ function applied row-wise\n",
        "\n",
        "**EXAMPLE:**\n"
      ],
      "metadata": {
        "id": "MlMVQn0dd6t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [10, 20, 30]\n",
        "})\n",
        "\n",
        "# Apply on Series\n",
        "print(df['A'].apply(lambda x: x**2))\n",
        "\n",
        "# Apply on DataFrame (column-wise sum)\n",
        "print(df.apply(sum, axis=0))\n",
        "\n",
        "# Apply on DataFrame (row-wise sum)\n",
        "print(df.apply(sum, axis=1))"
      ],
      "metadata": {
        "id": "1AsRpiN_eFdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18.What are some advanced features of NumPy?**\n",
        "\n",
        "NumPy isnâ€™t just about arrays and basic math â€” it has advanced features that make it powerful for scientific computing, machine learning, and data processing. Here are some of the most important ones:\n",
        "\n",
        "**1. Broadcasting**\n",
        "- Allows arithmetic operations between arrays of different shapes without explicit looping.\n",
        "\n",
        "**2. Vectorization**\n",
        "\n",
        "- Replaces Python loops with fast, low-level C implementations.\n",
        "\n",
        "- Makes operations much faster than using for loops."
      ],
      "metadata": {
        "id": "RnbR0AL-eLvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "print(arr[[0, 3]])          # Fancy indexing â†’ [10 40]\n",
        "print(arr[arr > 25])        # Boolean indexing â†’ [30 40 50]"
      ],
      "metadata": {
        "id": "VtpSyX4Kefet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Fancy Indexing & Boolean Indexing**\n",
        "- Select elements using arrays of indices or conditions.\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "QxGgP9FkekFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([10, 20, 30, 40, 50])\n",
        "print(arr[[0, 3]])          # Fancy indexing â†’ [10 40]\n",
        "print(arr[arr > 25])        # Boolean indexing â†’ [30 40 50]"
      ],
      "metadata": {
        "id": "Ks6Kwc6ieuKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Structured Arrays & Record Arrays**\n",
        "\n",
        "- Store heterogeneous data (like tables) in a single NumPy array.\n",
        "\n",
        "**EXAMPLE**:"
      ],
      "metadata": {
        "id": "f60Gkr5EgA5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([(1, 'Alice', 3.5),\n",
        "                 (2, 'Bob', 7.2)],\n",
        "                dtype=[('id', 'i4'), ('name', 'U10'), ('score', 'f4')])\n",
        "print(data['name'])"
      ],
      "metadata": {
        "id": "77kU60E-gCe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **5. Universal Functions** (ufuncs)\n",
        "\n",
        "- Highly optimized element-wise functions (e.g., np.sin, np.exp, np.add).\n",
        "\n",
        "- Support broadcasting and can be combined with reduce, accumulate, outer.\n",
        "\n",
        "**EXAMPLE:**"
      ],
      "metadata": {
        "id": "9xaIhBGpgHOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3])\n",
        "print(np.add.reduce(x))  # sum â†’ 6"
      ],
      "metadata": {
        "id": "giG4O9mbgL1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19.How does Pandas simplify time series analysis?**\n",
        "Pandas was originally built with time **series analysis in mind**, so it provides a lot of **tools** that make working with dates, times, and indexed data much simpler compared to plain Python.\n",
        "\n",
        "**1. Date and Time Indexing**\n",
        "\n",
        "- Pandas has a special DatetimeIndex that lets you use dates and times as the index.\n",
        "\n",
        "- This allows label-based indexing with time stamps."
      ],
      "metadata": {
        "id": "LD1tV4eGgPRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a time series\n",
        "dates = pd.date_range(\"2025-01-01\", periods=5, freq=\"D\")\n",
        "ts = pd.Series([10, 20, 30, 40, 50], index=dates)\n",
        "\n",
        "print(ts[\"2025-01-03\"])   # Access by date â†’ 30\n",
        "print(ts[\"2025-01\"])      # Slice by month"
      ],
      "metadata": {
        "id": "e01R3LPXgywV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Resampling and Frequency Conversion**\n",
        "\n",
        "- Easily convert data between frequencies (e.g., daily â†’ monthly, hourly â†’ daily).\n",
        "\n",
        "- Supports aggregation (mean, sum, etc.) and upsampling/downsampling.\n",
        "\n",
        "\n",
        "print(ts.resample(\"M\").mean())  # Monthly average\n",
        "\n",
        "\n",
        "**3. Shifting and Lagging**\n",
        "\n",
        "- You can shift data forward or backward in time to calculate changes, returns, etc.\n"
      ],
      "metadata": {
        "id": "TU-Rsrs0g_Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ts.shift(1))    # Lagged values\n",
        "print(ts.diff())      # First difference\n"
      ],
      "metadata": {
        "id": "R-W3jwwrh1Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **4. Rolling, Expanding, and Moving Windows**\n",
        "\n",
        "- Built-in support for rolling statistics, moving averages, expanding windows.\n"
      ],
      "metadata": {
        "id": "FjZ2dsfZh2db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ts.rolling(window=3).mean())  # 3-day moving average"
      ],
      "metadata": {
        "id": "iigu9WASh7Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Time Zone Handling**\n",
        "\n",
        "- Pandas supports time zoneâ€“aware DatetimeIndex objects and conversion."
      ],
      "metadata": {
        "id": "MKok7dSLh_O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_utc = ts.tz_localize(\"UTC\")\n",
        "print(ts_utc.tz_convert(\"Asia/Kolkata\"))"
      ],
      "metadata": {
        "id": "zHY9XsjMiHIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20.What is the role of a pivot table in Pandas?**\n",
        "\n",
        "In Pandas, a pivot table plays the role of a powerful tool for summarizing, aggregating, and reorganizing data â€” very similar to pivot tables in Excel.\n",
        "\n",
        " **Role of a Pivot Table in Pandas**\n",
        "\n",
        "**1.Data Summarization**\n",
        "\n",
        "- Pivot tables group data by one or more keys (rows/columns) and apply an aggregation function (like mean, sum, count, etc.).\n",
        "\n",
        "- This helps in quickly getting insights from large datasets.\n",
        "\n",
        "**2.Reshaping Data**\n",
        "\n",
        "- Transforms data from long format to wide format.\n",
        "\n",
        "- Useful for cross-tabulations and comparisons between categories.\n",
        "\n",
        "**3.Aggregation and Statistics**\n",
        "\n",
        "- Supports multiple aggregation functions (mean, sum, min, max, count).\n",
        "\n",
        "- Can show multiple aggregations at once.\n",
        "\n",
        "**4.Multi-level Grouping**\n",
        "\n",
        "- Allows grouping by multiple columns (hierarchical indexing).\n",
        "\n",
        "- Helps analyze data across several dimensions.\n",
        "\n",
        "\n",
        "**EXAMPLE**:\n"
      ],
      "metadata": {
        "id": "shVV9eHTiK5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Department': ['Sales', 'Sales', 'HR', 'HR', 'IT', 'IT'],\n",
        "    'Employee': ['A', 'B', 'C', 'D', 'E', 'F'],\n",
        "    'Salary': [5000, 6000, 4500, 4800, 7000, 7200],\n",
        "    'Bonus': [500, 600, 300, 400, 800, 900]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a pivot table\n",
        "pivot = pd.pivot_table(df,\n",
        "                       values=['Salary', 'Bonus'],\n",
        "                       index='Department',\n",
        "                       aggfunc={'Salary': 'mean', 'Bonus': 'sum'})\n",
        "\n",
        "print(pivot)"
      ],
      "metadata": {
        "id": "sEm1aWKIiXaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21.Why is NumPyâ€™s array slicing faster than Pythonâ€™s list slicing?**\n",
        "\n",
        "NumPyâ€™s array slicing is much faster than **Pythonâ€™s built-in list slicing**, and the main reasons come from how they are implemented under the hood.\n",
        "\n",
        "ðŸ”¹ **1. Memory Layout**\n",
        "\n",
        "- **Python lists:**\n",
        "\n",
        "- A list is an array of **pointers to objects scattered** in memory.\n",
        "\n",
        "- **Slicing a list creates** a new list with copies of references (extra overhead).\n",
        "\n",
        "- **NumPy arrays:**\n",
        "\n",
        "- Stored as a **contiguous block of memory** (like a C array).\n",
        "\n",
        "- Slicing does not **copy data; instead, it creates a view into the same memory buffer using strides**.\n",
        "\n",
        "- This makes slicing constant-time (no data copying).\n",
        "\n",
        "ðŸ”¹ **2. Views vs Copies**\n",
        "\n",
        "- **Python list slicing â†’** Always makes a new object (copy of references).\n",
        "\n",
        "- **NumPy array slicing â†’** Returns a view (unless explicitly copied).\n",
        "\n"
      ],
      "metadata": {
        "id": "Va5PShcKigr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.arange(10)\n",
        "slice_arr = arr[2:6]   # view, no data copied\n",
        "slice_arr[0] = 99\n",
        "print(arr)             # original array also changes"
      ],
      "metadata": {
        "id": "3FHUPEaNiriA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Vectorized Implementation**\n",
        "\n",
        "- NumPy is built on C and Fortran libraries (BLAS/LAPACK).\n",
        "\n",
        "- Slicing just adjusts pointers and strides instead of looping over elements.\n",
        "\n",
        "- Python **lists, being high-level,** need to loop element by element in pure Python â†’ slower.\n",
        "\n",
        " **4. Data Type Uniformity**\n",
        "\n",
        "- NumPy arrays have a single data type (dtype), which allows efficient pointer arithmetic.\n",
        "\n",
        "- Python lists can contain mixed types, so slicing needs type checks and extra overhead."
      ],
      "metadata": {
        "id": "UYI__YJ4iwPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22.What are some common use cases for Seaborn?**\n",
        "\n",
        "**Seaborn is a Python data visualization library** built on top of Matplotlib, designed for making statistical **graphics easier and prettier**. Itâ€™s widely used in data analysis and machine learning workflows.\n",
        "\n",
        " **1. Exploratory Data Analysis** (EDA)\n",
        "\n",
        "- Quickly understand **distributions, relationships, and patterns** in datasets.\n",
        "\n",
        "- **Example:** visualizing the spread of numerical variables or comparing categories.\n",
        "\n",
        " **2. Visualizing Distributions**\n",
        "\n",
        "- Functions like histplot(), kdeplot(), distplot() (deprecated) show probability distributions.\n",
        "\n",
        "- Useful for detecting skewness, outliers, and spread of data.\n"
      ],
      "metadata": {
        "id": "MKu6PurEi5de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(data=[1,2,2,3,3,3,4,4,5], kde=True)"
      ],
      "metadata": {
        "id": "Ng8uIy37jP9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **3. Comparing Categories**\n",
        "\n",
        "- Bar plots, count plots, and box plots for categorical data analysis.\n",
        "\n",
        "- Great for understanding differences between groups\n",
        "\n",
        "sns.boxplot(x=\"species\", y=\"sepal_length\", data=sns.load_dataset(\"iris\"))\n",
        "\n",
        "\n",
        "**4. Relationship Analysis**\n",
        "\n",
        "- Scatter plots, regression lines (lmplot, regplot) to analyze correlation between variables.\n",
        "\n",
        "sns.lmplot(x=\"sepal_length\", y=\"petal_length\", data=sns.load_dataset(\"iris\"))\n",
        "\n",
        "\n",
        "**5. Heatmaps & Correlation Analysis**\n",
        "\n",
        "- heatmap() is often used to visualize correlation matrices in feature analysis\n"
      ],
      "metadata": {
        "id": "iwf921VqjTtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "# Drop the non-numerical 'species' column before calculating correlation\n",
        "sns.heatmap(iris.drop('species', axis=1).corr(), annot=True, cmap=\"coolwarm\")"
      ],
      "metadata": {
        "id": "yFBn10MfjeJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICAL"
      ],
      "metadata": {
        "id": "bQVVw3pdjjco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "**Q1.How do you create a 2D NumPy array and calculate the sum of each row?**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create a 2D NumPy array\n",
        "array_2d = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6],\n",
        "                     [7, 8, 9]])\n",
        "\n",
        "print(\"2D NumPy Array:\")\n",
        "print(array_2d)\n",
        "\n",
        "# Calculate the sum of each row\n",
        "# The axis=1 argument specifies that the sum should be calculated across columns (for each row)\n",
        "row_sums = np.sum(array_2d, axis=1)\n",
        "\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n"
      ],
      "metadata": {
        "id": "qJLo9BLJjmGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q2.Write a Pandas script to find the mean of a specific column in a DataFrame?**\n",
        "\n",
        "# Find the mean of a specific column (e.g., 'Salary')\n",
        "mean_salary = df['Salary'].mean()\n",
        "\n",
        "print(f\"The mean salary is: {mean_salary}\")"
      ],
      "metadata": {
        "id": "H6QUTi_Qj9Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q3.Create a scatter plot using Matplotlib?**\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Often used with matplotlib for datasets and styling\n",
        "\n",
        "# Load the iris dataset if not already loaded (though it is in this notebook)\n",
        "# iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6)) # Optional: set figure size\n",
        "plt.scatter(iris['sepal_length'], iris['sepal_width'], alpha=0.7) # alpha for transparency\n",
        "plt.title('Scatter Plot of Sepal Length vs Sepal Width (Iris Dataset)')\n",
        "plt.xlabel('Sepal Length (cm)')\n",
        "plt.ylabel('Sepal Width (cm)')\n",
        "plt.grid(True) # Optional: add a grid\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "enUjcsRJjwA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q4.How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?**\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the iris dataset (if not already loaded)\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Calculate the correlation matrix, excluding the non-numerical 'species' column\n",
        "correlation_matrix = iris.drop('species', axis=1).corr()\n",
        "\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(8, 6)) # Optional: set figure size\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\") # annot shows values, fmt formats them\n",
        "plt.title('Correlation Heatmap of Iris Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iYexu9UfkG6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q5.Generate a bar plot using Plotly?**\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# Use the 'pivot' DataFrame created earlier for department-wise sums\n",
        "# Or use the original df and group by department to calculate the sum\n",
        "# Here, I'll use the original df and group by department to get the sum of salaries\n",
        "department_salary_sum = df.groupby('Department')['Salary'].sum().reset_index()\n",
        "\n",
        "# Create a bar plot using Plotly Express\n",
        "fig = px.bar(department_salary_sum,\n",
        "             x='Department',\n",
        "             y='Salary',\n",
        "             title='Total Salary by Department')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-M1KvJiQkl-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q6.Create a DataFrame and add a new column based on an existing column?**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {'Numbers': [1, 2, 3, 4, 5]}\n",
        "df_new = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df_new)\n",
        "\n",
        "# Add a new column 'Squared' based on the 'Numbers' column\n",
        "df_new['Squared'] = df_new['Numbers'] ** 2\n",
        "\n",
        "print(\"\\nDataFrame with new column:\")\n",
        "print(df_new)\n"
      ],
      "metadata": {
        "id": "69-dku0uk4KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q7.Write a program to perform element-wise multiplication of two NumPy arrays?**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two NumPy arrays\n",
        "array1 = np.array([[1, 2],\n",
        "                   [3, 4]])\n",
        "\n",
        "array2 = np.array([[5, 6],\n",
        "                   [7, 8]])\n",
        "\n",
        "print(\"Array 1:\")\n",
        "print(array1)\n",
        "\n",
        "print(\"\\nArray 2:\")\n",
        "print(array2)\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result_array = array1 * array2\n",
        "\n",
        "print(\"\\nResult of element-wise multiplication:\")\n",
        "print(result_array)"
      ],
      "metadata": {
        "id": "8hXK674MlA7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q8.Create a line plot with multiple lines using Matplotlib?**\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "x = np.array([1, 2, 3, 4, 5])\n",
        "y1 = np.array([2, 4, 6, 8, 10])\n",
        "y2 = np.array([1, 3, 5, 7, 9])\n",
        "y3 = np.array([5, 2, 8, 3, 7])\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6)) # Optional: set figure size\n",
        "\n",
        "plt.plot(x, y1, marker='o', linestyle='-', color='blue', label='Line 1')\n",
        "plt.plot(x, y2, marker='x', linestyle='--', color='red', label='Line 2')\n",
        "plt.plot(x, y3, marker='s', linestyle='-.', color='green', label='Line 3')\n",
        "\n",
        "plt.title('Line Plot with Multiple Lines')\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.legend() # Show the legend to identify lines\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0RwLivs1lI85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q9.A Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold?**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Numbers': [10, 25, 5, 40, 15, 30]}\n",
        "df_filter = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df_filter)\n",
        "\n",
        "# Define a threshold\n",
        "threshold = 20\n",
        "\n",
        "# Filter rows where the 'Numbers' column is greater than the threshold\n",
        "filtered_df = df_filter[df_filter['Numbers'] > threshold]\n",
        "\n",
        "print(f\"\\nDataFrame filtered for 'Numbers' > {threshold}:\")\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "dWXYK80JlbfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q10.Create a histogram using Seaborn to visualize a distribution?\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create some sample data for the histogram\n",
        "data_for_histogram = [1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 5, 6, 6, 7]\n",
        "\n",
        "# Create the histogram using Seaborn's histplot\n",
        "plt.figure(figsize=(8, 6)) # Optional: set figure size\n",
        "sns.histplot(data=data_for_histogram, kde=True) # kde=True adds a kernel density estimate line\n",
        "plt.title('Distribution of Sample Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HB0kXAlnlh0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q11.Perform matrix multiplication using NumPy?**\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Create two NumPy matrices (2D arrays)\n",
        "matrix1 = np.array([[1, 2],\n",
        "                    [3, 4]])\n",
        "\n",
        "matrix2 = np.array([[5, 6],\n",
        "                    [7, 8]])\n",
        "\n",
        "print(\"Matrix 1:\")\n",
        "print(matrix1)\n",
        "\n",
        "print(\"\\nMatrix 2:\")\n",
        "print(matrix2)\n",
        "\n",
        "# Perform matrix multiplication using the @ operator (preferred in Python 3.5+)\n",
        "result_matrix = matrix1 @ matrix2\n",
        "\n",
        "# Alternatively, using np.dot()\n",
        "# result_matrix = np.dot(matrix1, matrix2)\n",
        "\n",
        "print(\"\\nResult of matrix multiplication:\")\n",
        "print(result_matrix)\n"
      ],
      "metadata": {
        "id": "g6mdriIol5r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q12.Use Pandas to load a CSV file and display its first 5 rows?**\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'sample.csv' with the actual path to your CSV file\n",
        "try:\n",
        "    df_csv = pd.read_csv('sample.csv')\n",
        "\n",
        "    print(\"DataFrame loaded from CSV:\")\n",
        "    # Display the first 5 rows\n",
        "    display(df_csv.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'sample.csv' not found. Please replace 'sample.csv' with the correct path to your file.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "-cBSZctfl_CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "**Q13.Create a 3D scatter plot using Plotly?**\n",
        "\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the iris dataset if not already loaded\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = px.scatter_3d(iris,\n",
        "                    x='sepal_length',\n",
        "                    y='sepal_width',\n",
        "                    z='petal_length',\n",
        "                    color='species',\n",
        "                    title='3D Scatter Plot of Iris Dataset')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "w9p_0catmNLV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}